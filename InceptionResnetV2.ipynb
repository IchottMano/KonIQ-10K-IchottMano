{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResnetV2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_fpB1pkU5Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Reference\n",
        "- [Inception-v4, Inception-ResNet and the Impact of\n",
        "   Residual Connections on Learning](https://arxiv.org/abs/1602.07261) (AAAI 2017)\n",
        "- Most code is from https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_resnet_v2.py\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "keras = tf.keras\n",
        "\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras_applications.imagenet_utils import preprocess_input\n",
        "from keras_applications import get_submodules_from_kwargs\n",
        "\n",
        "backend = None\n",
        "layers = None\n",
        "models = None\n",
        "keras_utils = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVlGk7tVW-hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_input(x, **kwargs):\n",
        "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
        "    # Returns\n",
        "        Preprocessed array.\n",
        "    \"\"\"\n",
        "    return preprocess_input(x, mode='tf', **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd_onGTqXWes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              kernel_size,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              use_bias=False,\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        kernel_size: kernel size as in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        activation: activation in `Conv2D`.\n",
        "        use_bias: whether to use a bias in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_ac'` for the activation\n",
        "            and `name + '_bn'` for the batch norm layer.\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(filters,\n",
        "                      kernel_size,\n",
        "                      strides=strides,\n",
        "                      padding=padding,\n",
        "                      use_bias=use_bias,\n",
        "                      name=name)(x)\n",
        "    if not use_bias:\n",
        "        bn_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
        "        bn_name = None if name is None else name + '_bn'\n",
        "        x = layers.BatchNormalization(axis=bn_axis,\n",
        "                                      scale=False,\n",
        "                                      name=bn_name)(x)\n",
        "    if activation is not None:\n",
        "        ac_name = None if name is None else name + '_ac'\n",
        "        x = layers.Activation(activation, name=ac_name)(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GhjY19XstE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
        "    \"\"\"Adds a Inception-ResNet block.\n",
        "    This function builds 3 types of Inception-ResNet blocks mentioned\n",
        "    in the paper, controlled by the `block_type` argument (which is the\n",
        "    block name used in the official TF-slim implementation):\n",
        "        - Inception-ResNet-A: `block_type='block35'`\n",
        "        - Inception-ResNet-B: `block_type='block17'`\n",
        "        - Inception-ResNet-C: `block_type='block8'`\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        scale: scaling factor to scale the residuals (i.e., the output of\n",
        "            passing `x` through an inception module) before adding them\n",
        "            to the shortcut branch.\n",
        "            Let `r` be the output from the residual branch,\n",
        "            the output of this block will be `x + scale * r`.\n",
        "        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n",
        "            the network structure in the residual branch.\n",
        "        block_idx: an `int` used for generating layer names.\n",
        "            The Inception-ResNet blocks\n",
        "            are repeated many times in this network.\n",
        "            We use `block_idx` to identify\n",
        "            each of the repetitions. For example,\n",
        "            the first Inception-ResNet-A block\n",
        "            will have `block_type='block35', block_idx=0`,\n",
        "            and the layer names will have\n",
        "            a common prefix `'block35_0'`.\n",
        "        activation: activation function to use at the end of the block\n",
        "            (see [activations](../activations.md)).\n",
        "            When `activation=None`, no activation is applied\n",
        "            (i.e., \"linear\" activation: `a(x) = x`).\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    # Raises\n",
        "        ValueError: if `block_type` is not one of `'block35'`,\n",
        "            `'block17'` or `'block8'`.\n",
        "    \"\"\"\n",
        "    if block_type == 'block35':\n",
        "        branch_0 = conv2d_bn(x, 32, 1)\n",
        "        branch_1 = conv2d_bn(x, 32, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 32, 3)\n",
        "        branch_2 = conv2d_bn(x, 32, 1)\n",
        "        branch_2 = conv2d_bn(branch_2, 48, 3)\n",
        "        branch_2 = conv2d_bn(branch_2, 64, 3)\n",
        "        branches = [branch_0, branch_1, branch_2]\n",
        "    elif block_type == 'block17':\n",
        "        branch_0 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(x, 128, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n",
        "        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    elif block_type == 'block8':\n",
        "        branch_0 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n",
        "        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    else:\n",
        "        raise ValueError('Unknown Inception-ResNet block type. '\n",
        "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
        "                         'but got: ' + str(block_type))\n",
        "\n",
        "    block_name = block_type + '_' + str(block_idx)\n",
        "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
        "    mixed = layers.Concatenate(\n",
        "        axis=channel_axis, name=block_name + '_mixed')(branches)\n",
        "    up = conv2d_bn(mixed,\n",
        "                   backend.int_shape(x)[channel_axis],\n",
        "                   1,\n",
        "                   activation=None,\n",
        "                   use_bias=True,\n",
        "                   name=block_name + '_conv')\n",
        "\n",
        "    x = layers.Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=backend.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=block_name)([x, up])\n",
        "    if activation is not None:\n",
        "        x = layers.Activation(activation, name=block_name + '_ac')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrRh_-jMX0Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def InceptionResNetV2(include_top=True,\n",
        "                      input_tensor=None,\n",
        "                      input_shape=None,\n",
        "                      weights=None,\n",
        "                      **kwargs):\n",
        "    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is `False` (otherwise the input shape\n",
        "            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n",
        "            or `(3, 299, 299)` (with `'channels_first'` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 75.\n",
        "            E.g. `(150, 150, 3)` would be one valid value.\n",
        "    # Returns\n",
        "        A Keras `Model` instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    global backend, layers, models, keras_utils\n",
        "    backend = keras.backend\n",
        "    layers  = keras.layers\n",
        "    models  = keras.models\n",
        "    utils   = keras.utils\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(\n",
        "        input_shape,\n",
        "        default_size=299,\n",
        "        min_size=75,\n",
        "        data_format=backend.image_data_format(),\n",
        "        require_flatten=include_top,\n",
        "        weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    # Stem block: 35 x 35 x 192\n",
        "    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n",
        "    x = conv2d_bn(x, 32, 3, padding='valid')\n",
        "    x = conv2d_bn(x, 64, 3)\n",
        "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "    x = conv2d_bn(x, 80, 1, padding='valid')\n",
        "    x = conv2d_bn(x, 192, 3, padding='valid')\n",
        "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "\n",
        "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
        "    branch_0 = conv2d_bn(x, 96, 1)\n",
        "    branch_1 = conv2d_bn(x, 48, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 5)\n",
        "    branch_2 = conv2d_bn(x, 64, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
        "    branch_pool = layers.AveragePooling2D(3, strides=1, padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
        "    x = layers.Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
        "\n",
        "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
        "    for block_idx in range(1, 11):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.17,\n",
        "                                   block_type='block35',\n",
        "                                   block_idx=block_idx)\n",
        "\n",
        "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
        "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n",
        "    branch_1 = conv2d_bn(x, 256, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n",
        "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
        "    branches = [branch_0, branch_1, branch_pool]\n",
        "    x = layers.Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
        "\n",
        "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
        "    for block_idx in range(1, 21):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.1,\n",
        "                                   block_type='block17',\n",
        "                                   block_idx=block_idx)\n",
        "\n",
        "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
        "    branch_0 = conv2d_bn(x, 256, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n",
        "    branch_1 = conv2d_bn(x, 256, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n",
        "    branch_2 = conv2d_bn(x, 256, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 288, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n",
        "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    x = layers.Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
        "\n",
        "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
        "    for block_idx in range(1, 10):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.2,\n",
        "                                   block_type='block8',\n",
        "                                   block_idx=block_idx)\n",
        "    x = inception_resnet_block(x,\n",
        "                               scale=1.,\n",
        "                               activation=None,\n",
        "                               block_type='block8',\n",
        "                               block_idx=10)\n",
        "\n",
        "    # Final convolution block: 8 x 8 x 1536\n",
        "    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = layers.Dense(2048, activation='relu', name='predictions_2048')(x)\n",
        "        x = layers.Dense(1024, activation='relu', name='predictions_1024')(x)\n",
        "        x = layers.Dense(256, activation='relu', name='predictions_256')(x)\n",
        "        x = layers.Dense(1, activation='relu', name='prediction')(x)\n",
        "    else:\n",
        "        x = layers.GlobalAveragePooling2D()(x)\n",
        "        x = layers.Dense(2048, activation='relu', name='predictions_2048')(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='inception_resnet_v2')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "955fal9tZzs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a244802d-683a-43d7-842b-fb1d0c404464"
      },
      "source": [
        "model = InceptionResNetV2()\n",
        "model.compile(omptimizer=\"adam\", loss=keras.losses.Huber, metrics=[\"accuracy\", \"mse\"])\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}